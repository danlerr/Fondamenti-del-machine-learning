{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>BS</th>\n",
       "      <th>BodyTemp</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>RiskLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>86</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>140</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>78</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>69</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>110</td>\n",
       "      <td>89</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>701</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>90</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>701</td>\n",
       "      <td>98</td>\n",
       "      <td>80</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>98</td>\n",
       "      <td>90</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>mid risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>80</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>66</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>49</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>82</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SystolicBP  DiastolicBP   BS  BodyTemp  HeartRate  RiskLevel\n",
       "0    25         130           80   15        98         86  high risk\n",
       "1    35         140           90   13        98         70  high risk\n",
       "2    29          90           70    8       100         80  high risk\n",
       "3    30         140           85    7        98         70  high risk\n",
       "4    35         120           60   61        98         76   low risk\n",
       "5    23         140           80  701        98         70  high risk\n",
       "6    23         130           70  701        98         78   mid risk\n",
       "7    35          85           60   11       102         86  high risk\n",
       "8    32         120           90   69        98         70   mid risk\n",
       "9    42         130           80   18        98         70  high risk\n",
       "10   23          90           60  701        98         76   low risk\n",
       "11   19         120           80    7        98         70   mid risk\n",
       "12   25         110           89  701        98         77   low risk\n",
       "13   20         120           75  701       100         70   mid risk\n",
       "14   48         120           80   11        98         88   mid risk\n",
       "15   15         120           80  701        98         70   low risk\n",
       "16   50         140           90   15        98         90  high risk\n",
       "17   25         140          100  701        98         80  high risk\n",
       "18   30         120           80   69       101         76   mid risk\n",
       "19   10          70           50   69        98         70   low risk\n",
       "20   40         140          100   18        98         90  high risk\n",
       "21   50         140           80   67        98         70   mid risk\n",
       "22   21          90           65   75        98         76   low risk\n",
       "23   18          90           60   75        98         70   low risk\n",
       "24   21         120           80   75        98         76   low risk\n",
       "25   16         100           70   72        98         80   low risk\n",
       "26   19         120           75   72        98         66   low risk\n",
       "27   22         100           65   72        98         70   low risk\n",
       "28   49         120           90   72        98         77   low risk\n",
       "29   28          90           60   72        98         82   low risk"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "manuale  = pd.read_csv('manuale.csv', sep=';')\n",
    "manuale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#701???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La formula della distanza euclidea tra due punti in uno spazio n-dimensionale è:\n",
    "\n",
    "$$\n",
    "d(p_1, p_2) = \\sqrt{\\sum_{i=1}^{n} (p_{1,i} - p_{2,i})^2}\n",
    "$$\n",
    "\n",
    "Per uno spazio bidimensionale, la formula diventa:\n",
    "\n",
    "$$\n",
    "d(p_1, p_2) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1) - 1):  # Escludere l'ultima colonna (la classe target)\n",
    "        distance += (row1[i] - row2[i]) ** 2\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione knn_predict implementa l’algoritmo KNN. Dato un set di punti di training  X , le rispettive etichette  y , un set di punti di test e  k , restituisce le predizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def knn_predict(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        # Calcola la distanza tra il punto di test e tutti i punti di training\n",
    "        distances = [(euclidean_distance(test_point, x_train), y_train[i]) for i, x_train in enumerate(X_train)]\n",
    "        # Ordina le distanze in ordine crescente\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        # Seleziona i primi k vicini\n",
    "        k_nearest = [dist[1] for dist in distances[:k]]\n",
    "        # Predici la classe in base alla votazione a maggioranza\n",
    "        most_common = Counter(k_nearest).most_common(1)[0][0]\n",
    "        predictions.append(most_common)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation con k-fold divide il dataset in  k -fold, usa ciascun fold come test set una volta, mentre il resto dei fold viene usato come training set. Calcola l’accuratezza media su tutti i fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per suddividere i dati in k-fold\n",
    "def k_fold_split(X, y, k):\n",
    "    fold_size = len(X) // k\n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    for i in range(k):\n",
    "        X_folds.append(X[i * fold_size: (i + 1) * fold_size])\n",
    "        y_folds.append(y[i * fold_size: (i + 1) * fold_size])\n",
    "    return X_folds, y_folds\n",
    "\n",
    "def cross_validate_knn(X, y, k_neighbors, num_folds=5):\n",
    "    X_folds, y_folds = k_fold_split(X, y, num_folds)\n",
    "    \n",
    "    accuracies = []  # Per memorizzare le accuratezze per ciascun fold\n",
    "    for i in range(num_folds):\n",
    "        # Usa il fold i-esimo come test set\n",
    "        X_test_fold = X_folds[i]\n",
    "        y_test_fold = y_folds[i]\n",
    "        \n",
    "        # Usa tutti gli altri fold come training set\n",
    "        X_train_folds = np.concatenate([X_folds[j] for j in range(num_folds) if j != i])\n",
    "        y_train_folds = np.concatenate([y_folds[j] for j in range(num_folds) if j != i])\n",
    "        \n",
    "        # Prevedi con KNN\n",
    "        y_pred = knn_predict(X_train_folds, y_train_folds, X_test_fold, k_neighbors)\n",
    "        \n",
    "        # Calcola l'accuratezza per questo fold\n",
    "        accuracy = np.mean(np.array(y_pred) == np.array(y_test_fold))\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Restituisci l'accuratezza media sui fold\n",
    "    return np.mean(accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione trova il miglior  k  testando diversi valori di  k  e valutando le prestazioni medie tramite cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X, y, k_values, num_folds=5):\n",
    "    best_k = k_values[0]\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Esegui la cross-validation per ciascun k\n",
    "        accuracy = cross_validate_knn(X, y, k, num_folds)\n",
    "        print(f'Accuracy for k={k}: {accuracy:.4f}')\n",
    "        \n",
    "        # Se l'accuratezza per questo k è migliore, aggiorna il miglior k\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "    \n",
    "    print(f'Miglior valore di k: {best_k} con un\\'accuratezza di {best_accuracy:.4f}')\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=1: 0.5667\n",
      "Accuracy for k=2: 0.5667\n",
      "Accuracy for k=3: 0.5667\n",
      "Accuracy for k=4: 0.5667\n",
      "Accuracy for k=5: 0.6333\n",
      "Accuracy for k=6: 0.6000\n",
      "Accuracy for k=7: 0.6333\n",
      "Accuracy for k=8: 0.6000\n",
      "Accuracy for k=9: 0.5667\n",
      "Accuracy for k=10: 0.5333\n",
      "Miglior valore di k: 5 con un'accuratezza di 0.6333\n",
      "Accuratezza finale sui dati (con k=5): 0.8333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Separa le feature (X) e le etichette (y)\n",
    "X = manuale.iloc[:, :-1].values  # Tutte le colonne tranne l'ultima (feature)\n",
    "y = manuale.iloc[:, -1].values    # L'ultima colonna (target)\n",
    "# Esegui la ricerca del miglior valore di k\n",
    "k_values = list(range(1, 11))  # Prova k da 1 a 10\n",
    "best_k = find_best_k(X, y, k_values, num_folds=5)  # Cross-validation a 5 fold\n",
    "\n",
    "# **Valutazione finale**: Usa il miglior k trovato per fare predizioni su tutto il dataset\n",
    "y_final_pred = knn_predict(X, y, X, best_k)\n",
    "\n",
    "# Calcola e stampa l'accuratezza finale usando lo stesso dataset\n",
    "final_accuracy = np.mean(y_final_pred == y)\n",
    "print(f'Accuratezza finale sui dati (con k={best_k}): {final_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati Normalizzati:\n",
      " [[0.375      0.85714286 0.6        0.01152738 0.         0.83333333]\n",
      " [0.625      1.         0.8        0.00864553 0.         0.16666667]\n",
      " [0.475      0.28571429 0.4        0.00144092 0.5        0.58333333]\n",
      " [0.5        1.         0.7        0.         0.         0.16666667]\n",
      " [0.625      0.71428571 0.2        0.0778098  0.         0.41666667]\n",
      " [0.325      1.         0.6        1.         0.         0.16666667]\n",
      " [0.325      0.85714286 0.4        1.         0.         0.5       ]\n",
      " [0.625      0.21428571 0.2        0.00576369 1.         0.83333333]\n",
      " [0.55       0.71428571 0.8        0.08933718 0.         0.16666667]\n",
      " [0.8        0.85714286 0.6        0.01585014 0.         0.16666667]\n",
      " [0.325      0.28571429 0.2        1.         0.         0.41666667]\n",
      " [0.225      0.71428571 0.6        0.         0.         0.16666667]\n",
      " [0.375      0.57142857 0.78       1.         0.         0.45833333]\n",
      " [0.25       0.71428571 0.5        1.         0.5        0.16666667]\n",
      " [0.95       0.71428571 0.6        0.00576369 0.         0.91666667]\n",
      " [0.125      0.71428571 0.6        1.         0.         0.16666667]\n",
      " [1.         1.         0.8        0.01152738 0.         1.        ]\n",
      " [0.375      1.         1.         1.         0.         0.58333333]\n",
      " [0.5        0.71428571 0.6        0.08933718 0.75       0.41666667]\n",
      " [0.         0.         0.         0.08933718 0.         0.16666667]\n",
      " [0.75       1.         1.         0.01585014 0.         1.        ]\n",
      " [1.         1.         0.6        0.08645533 0.         0.16666667]\n",
      " [0.275      0.28571429 0.3        0.09798271 0.         0.41666667]\n",
      " [0.2        0.28571429 0.2        0.09798271 0.         0.16666667]\n",
      " [0.275      0.71428571 0.6        0.09798271 0.         0.41666667]\n",
      " [0.15       0.42857143 0.4        0.09365994 0.         0.58333333]\n",
      " [0.225      0.71428571 0.5        0.09365994 0.         0.        ]\n",
      " [0.3        0.42857143 0.3        0.09365994 0.         0.16666667]\n",
      " [0.975      0.71428571 0.8        0.09365994 0.         0.45833333]\n",
      " [0.45       0.28571429 0.2        0.09365994 0.         0.66666667]]\n",
      "Accuracy for k=1: 0.5667\n",
      "Accuracy for k=2: 0.5667\n",
      "Accuracy for k=3: 0.5667\n",
      "Accuracy for k=4: 0.5667\n",
      "Accuracy for k=5: 0.6333\n",
      "Accuracy for k=6: 0.6000\n",
      "Accuracy for k=7: 0.6333\n",
      "Accuracy for k=8: 0.6000\n",
      "Accuracy for k=9: 0.5667\n",
      "Accuracy for k=10: 0.5333\n",
      "Miglior valore di k: 5 con un'accuratezza di 0.6333\n",
      "Accuratezza finale sui dati (con k=5): 0.8667\n"
     ]
    }
   ],
   "source": [
    "#proviamo a normalaizzare i dati:\n",
    "\n",
    "# Normalizzazione manuale\n",
    "def min_max_normalize(data):\n",
    "    # Calcola il minimo e il massimo per ogni colonna\n",
    "    data_min = np.min(data, axis=0)\n",
    "    data_max = np.max(data, axis=0)\n",
    "    \n",
    "    # Applica la formula della normalizzazione\n",
    "    normalized_data = (data - data_min) / (data_max - data_min)\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "# Separa le feature (X) e le etichette (y)\n",
    "X = manuale.iloc[:, :-1].values  # Tutte le colonne tranne l'ultima (feature)\n",
    "y = manuale.iloc[:, -1].values    # L'ultima colonna (target)\n",
    "\n",
    "normalized_manuale = min_max_normalize(X)\n",
    "print(\"Dati Normalizzati:\\n\", normalized_manuale)\n",
    "\n",
    "#applichiamo knn sul dataset normalizzato:\n",
    "\n",
    "\n",
    "# Esegui la ricerca del miglior valore di k\n",
    "k_values = list(range(1, 11))  # Prova k da 1 a 10\n",
    "best_k = find_best_k(X, y, k_values, num_folds=5)  # Cross-validation a 5 fold\n",
    "\n",
    "# **Valutazione finale**: Usa il miglior k trovato per fare predizioni su tutto il dataset\n",
    "y_final_pred = knn_predict(normalized_manuale, y, normalized_manuale, best_k)\n",
    "\n",
    "# Calcola e stampa l'accuratezza finale usando lo stesso dataset\n",
    "final_accuracy = np.mean(y_final_pred == y)\n",
    "print(f'Accuratezza finale sui dati (con k={best_k}): {final_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_parametri(X, y):\n",
    "    # Identifica le classi uniche\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Dictionario per contenere i parametri per ogni classe\n",
    "    parameters = {}\n",
    "    \n",
    "    # Calcola media, varianza e probabilità a priori per ogni classe\n",
    "    for cls in classes:\n",
    "        X_c = X[y == cls]  # Dati appartenenti alla classe corrente\n",
    "        parameters[cls] = {\n",
    "            'mean': X_c.mean(axis=0),  # Media di ciascuna feature\n",
    "            'var': X_c.var(axis=0),    # Varianza di ciascuna feature\n",
    "            'prior': X_c.shape[0] / X.shape[0]  # Probabilità a priori\n",
    "        }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_probability(x, mean, var):\n",
    "    # Aumenta epsilon per evitare varianze troppo piccole che causano problemi numerici\n",
    "    epsilon = 1e-1 # Valore piccolo ma più grande di quello precedente\n",
    "    coefficient = 1 / np.sqrt(2 * np.pi * (var + epsilon))\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * (var + epsilon)))\n",
    "    return coefficient * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probability(x, parameters):\n",
    "    probabilities = {}\n",
    "    \n",
    "    # Calcola la probabilità per ciascuna classe\n",
    "    for cls, params in parameters.items():\n",
    "        prior = np.log(params['prior'])  # Usa log per la probabilità a priori\n",
    "        likelihood = np.sum(np.log(gaussian_probability(x, params['mean'], params['var'])))\n",
    "        probabilities[cls] = prior + likelihood\n",
    "    \n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    predictions = []\n",
    "    # Per ogni esempio nei dati di input\n",
    "    for x in X:\n",
    "        class_probabilities = class_probability(x, parameters)\n",
    "        # Seleziona la classe con la probabilità a posteriori massima\n",
    "        predictions.append(max(class_probabilities, key=class_probabilities.get))\n",
    "    \n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni: ['high risk' 'high risk' 'high risk' 'high risk' 'low risk' 'low risk'\n",
      " 'low risk' 'high risk' 'low risk' 'mid risk' 'low risk' 'low risk'\n",
      " 'low risk' 'mid risk' 'high risk' 'low risk' 'high risk' 'high risk'\n",
      " 'mid risk' 'low risk' 'high risk' 'mid risk' 'low risk' 'low risk'\n",
      " 'low risk' 'low risk' 'low risk' 'low risk' 'mid risk' 'low risk']\n",
      "Etichette vere: ['high risk' 'high risk' 'high risk' 'high risk' 'low risk' 'high risk'\n",
      " 'mid risk' 'high risk' 'mid risk' 'high risk' 'low risk' 'mid risk'\n",
      " 'low risk' 'mid risk' 'mid risk' 'low risk' 'high risk' 'high risk'\n",
      " 'mid risk' 'low risk' 'high risk' 'mid risk' 'low risk' 'low risk'\n",
      " 'low risk' 'low risk' 'low risk' 'low risk' 'low risk' 'low risk']\n"
     ]
    }
   ],
   "source": [
    "# Calcola i parametri (media, varianza, probabilità a priori) per ogni classe\n",
    "parameters = calcola_parametri(X, y)\n",
    "\n",
    "# Prevedi le classi per i nuovi esempi o usa i dati esistenti per il test\n",
    "X_test = X  # Puoi usare i tuoi dati esistenti o nuovi esempi\n",
    "\n",
    "# Predici le classi\n",
    "predictions = predict(X_test, parameters)\n",
    "\n",
    "# Visualizza le predizioni\n",
    "print(\"Predizioni:\", predictions)\n",
    "\n",
    "# Confronta con le etichette vere (opzionale)\n",
    "print(\"Etichette vere:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)  # Conta le predizioni corrette\n",
    "    accuracy = correct_predictions / len(y_true)  # Divide per il numero totale di esempi\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Supponiamo che tu abbia le predizioni già pronte\n",
    "predictions = predict(X, parameters)  # Prevedi con il modello Gaussian Naive Bayes\n",
    "\n",
    "# Valuta l'accuracy\n",
    "accuracy = calculate_accuracy(y, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[ 8  1  1]\n",
      " [ 0 12  1]\n",
      " [ 1  3  3]]\n",
      "Etichette delle classi: ['high risk' 'low risk' 'mid risk']\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    # Identifica le classi uniche\n",
    "    classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    # Crea una matrice di confusione vuota\n",
    "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    \n",
    "    # Popola la matrice\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_index = np.where(classes == true)[0][0]  # Trova l'indice della classe vera\n",
    "        pred_index = np.where(classes == pred)[0][0]  # Trova l'indice della classe prevista\n",
    "        matrix[true_index, pred_index] += 1\n",
    "    \n",
    "    return matrix, classes\n",
    "\n",
    "# Usa la funzione per calcolare la matrice di confusione\n",
    "cm, classes = confusion_matrix(y, predictions)\n",
    "\n",
    "# Stampa la matrice di confusione\n",
    "print(\"Matrice di confusione:\")\n",
    "print(cm)\n",
    "\n",
    "# Opzionale: stampa le etichette delle classi\n",
    "print(\"Etichette delle classi:\", classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
