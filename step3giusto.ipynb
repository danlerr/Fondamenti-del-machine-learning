{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>BS</th>\n",
       "      <th>BodyTemp</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>RiskLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>86.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>70.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>90</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100</td>\n",
       "      <td>80.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>140</td>\n",
       "      <td>85.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>70.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>120</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>98</td>\n",
       "      <td>76.0</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>48.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>88.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>22.0</td>\n",
       "      <td>120</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>80.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>55.0</td>\n",
       "      <td>120</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>60.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>35.0</td>\n",
       "      <td>85</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>86.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>43.0</td>\n",
       "      <td>120</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>98</td>\n",
       "      <td>70.0</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
       "0     25.0         130         80.0  72.0        98       86.0  high risk\n",
       "1     35.0         140         90.0  72.0        98       70.0  high risk\n",
       "2     29.0          90         70.0  72.0       100       80.0  high risk\n",
       "3     30.0         140         85.0  72.0        98       70.0  high risk\n",
       "4     35.0         120         60.0  61.0        98       76.0   low risk\n",
       "...    ...         ...          ...   ...       ...        ...        ...\n",
       "1004  48.0         120         80.0  72.0        98       88.0  high risk\n",
       "1005  22.0         120         60.0  72.0        98       80.0  high risk\n",
       "1006  55.0         120         90.0  72.0        98       60.0  high risk\n",
       "1007  35.0          85         60.0  72.0        98       86.0  high risk\n",
       "1008  43.0         120         90.0  72.0        98       70.0  high risk\n",
       "\n",
       "[1009 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; \n",
    "data = pd.read_csv('training_c.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo i classificatori progettati manualmente nello step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo step utilizziamo scikit learn solo per standardizzare i dati e dividere il dataset in training set e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiamo dataset per training set e test set. Standardizziamo inoltre i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(\"RiskLevel\", axis=1)  # Features\n",
    "y = data['RiskLevel']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Standardizzazione\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertiamo y_train e y_test in array numpy\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi abbiamo il Training set (X_train, y_train) che è utilizzato per addestrare il modello. Il Test set (X_test, y_test) è utilizzato per valutare le prestazioni del modello.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Trova il miglior valore di k usando cross-validation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m k_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m))  \u001b[38;5;66;03m# Prova k da 1 a 10\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m best_k \u001b[38;5;241m=\u001b[39m find_best_k(X_train, y_train, k_values, num_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Cross-validation a 5 fold\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Predizione di y_test con il miglior valore di k\u001b[39;00m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn_predict(X_train, y_train, X_test, best_k)\n",
      "File \u001b[0;32m~/Desktop/Progetto machine/Progetto/Fondamenti-del-machine-learning/functions.py:64\u001b[0m, in \u001b[0;36mfind_best_k\u001b[0;34m(X, y, k_values, num_folds)\u001b[0m\n\u001b[1;32m     60\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Eseguiamo la cross-validation per ciascun k\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m cross_validate_knn(X, y, k, num_folds)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy for k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Se l'accuratezza per questo k è migliore, aggiorna il miglior k\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Progetto machine/Progetto/Fondamenti-del-machine-learning/functions.py:49\u001b[0m, in \u001b[0;36mcross_validate_knn\u001b[0;34m(X, y, k_neighbors, num_folds)\u001b[0m\n\u001b[1;32m     46\u001b[0m y_train_folds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y_folds[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_folds) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m i])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Prevedi con KNN\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn_predict(X_train_folds, y_train_folds, X_test_fold, k_neighbors)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Calcola l'accuratezza per questo fold\u001b[39;00m\n\u001b[1;32m     52\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray(y_pred) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test_fold))\n",
      "File \u001b[0;32m~/Desktop/Progetto machine/Progetto/Fondamenti-del-machine-learning/functions.py:16\u001b[0m, in \u001b[0;36mknn_predict\u001b[0;34m(X_train, y_train, X_test, k)\u001b[0m\n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_point \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Calcola la distanza tra il punto di test e tutti i punti di training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [(euclidean_distance(test_point, x_train), y_train[i]) \u001b[38;5;28;01mfor\u001b[39;00m i, x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_train)]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Ordina le distanze in ordine crescente\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     distances\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Progetto machine/Progetto/Fondamenti-del-machine-learning/functions.py:16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_point \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Calcola la distanza tra il punto di test e tutti i punti di training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [(euclidean_distance(test_point, x_train), y_train[i]) \u001b[38;5;28;01mfor\u001b[39;00m i, x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_train)]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Ordina le distanze in ordine crescente\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     distances\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Progetto machine/Progetto/Fondamenti-del-machine-learning/functions.py:9\u001b[0m, in \u001b[0;36meuclidean_distance\u001b[0;34m(row1, row2)\u001b[0m\n\u001b[1;32m      7\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row1) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# Escludere l'ultima colonna (la classe target)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (row1[i] \u001b[38;5;241m-\u001b[39m row2[i]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(distance)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# Trova il miglior valore di k usando cross-validation\n",
    "k_values = list(range(1, 11))  # Prova k da 1 a 10\n",
    "best_k = find_best_k(X_train, y_train, k_values, num_folds=5)  # Cross-validation a 5 fold\n",
    "\n",
    "# Predizione di y_test con il miglior valore di k\n",
    "y_pred = knn_predict(X_train, y_train, X_test, best_k)\n",
    "\n",
    "# Calcolo e stampa dell'accuratezza finale\n",
    "final_accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuratezza finale sui dati di test (con k={best_k}): {final_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred contiene le predizioni sul set di test.\n",
    "y_train contiene le etichette del set di training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
